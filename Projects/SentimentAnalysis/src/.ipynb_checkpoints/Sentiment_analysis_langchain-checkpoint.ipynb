{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3e67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.llms import GooglePalm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3e631",
   "metadata": {},
   "source": [
    "# Load DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4aca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file_path = \"../Data/Process/sample_test_data.xlsx\"\n",
    "df_test = pd.read_excel(processed_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6073709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes bad acting is not only one thing to mentio...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['yes', 'bad', 'acting', 'not', 'thing', 'ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hard to imagine what they were thinking of whe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['hard', 'imagine', 'think', 'movie', 'i.e.', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is a nightmare The sensation you fee...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['film', 'nightmare', 'sensation', 'feel', 'wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duchess is a pretty white cat who lives with h...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['Duchess', 'pretty', 'white', 'cat', 'live', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like anyone else who bought this I was duped b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['like', 'buy', 'dupe', 'piece', 'extreme', 'g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  Yes bad acting is not only one thing to mentio...  negative   \n",
       "1  Hard to imagine what they were thinking of whe...  negative   \n",
       "2  This film is a nightmare The sensation you fee...  negative   \n",
       "3  Duchess is a pretty white cat who lives with h...  positive   \n",
       "4  Like anyone else who bought this I was duped b...  negative   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  ['yes', 'bad', 'acting', 'not', 'thing', 'ment...  \n",
       "1  ['hard', 'imagine', 'think', 'movie', 'i.e.', ...  \n",
       "2  ['film', 'nightmare', 'sensation', 'feel', 'wa...  \n",
       "3  ['Duchess', 'pretty', 'white', 'cat', 'live', ...  \n",
       "4  ['like', 'buy', 'dupe', 'piece', 'extreme', 'g...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25419631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load environment variables from .env file\n",
    "# load_dotenv()\n",
    "# # Access the API key\n",
    "# google_palm_api_key = os.getenv('Google_palm_api_key')\n",
    "# llm = GooglePalm(google_api_key=api_key, temperature=0.4)\n",
    "# # classification_chain = load_qa_chain(llm=llm)\n",
    "\n",
    "\n",
    "\n",
    "# def get_sentiment(text):\n",
    "#     print(text)\n",
    "#     # Define the prompt template\n",
    "#     prompt_template = \"\"\"Given the review, ask as the NLP model to determine the sentiment of the below review: \"{text}\".\"\"\"\n",
    "\n",
    "#     # Generate the complete prompt by inserting the review text\n",
    "#     prompt = prompt_template.format(text=text)\n",
    "\n",
    "#     # Pass the prompt to the LLM\n",
    "#     classification = llm(prompt)\n",
    "    \n",
    "#     return classification\n",
    "\n",
    "# # df_test['pred_review'] = df_test['review'].apply(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "626a6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['len_review'] = df_test['review'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "869d0ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232.616"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['len_review'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d06994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e543db72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\AppData\\Local\\Temp\\ipykernel_15192\\3064228076.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\AppData\\Local\\Temp\\ipykernel_15192\\3064228076.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\AppData\\Local\\Temp\\ipykernel_15192\\3064228076.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 accuracy: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Pause for a few seconds to avoid HTTP limit errors\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Calculate overall accuracy\u001b[39;00m\n\u001b[0;32m     46\u001b[0m overall_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(accuracy_list) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(accuracy_list)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Access the Hugging Face API key\n",
    "huggingface_api_key = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Initialize the LLM with Hugging Face\n",
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=huggingface_api_key,\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\": 0.1},\n",
    "    task=\"text2text-generation\"\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Given the review, determine the sentiment of the below review: {text}\"\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ") \n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_review(review):\n",
    "    result = chain.run(text=review)\n",
    "    return result.strip().lower()\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(0, len(df_test), 10):\n",
    "    batch_df = df_test.iloc[i:i+10]\n",
    "    \n",
    "    batch_df.loc['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n",
    "    \n",
    "    batch_accuracy = batch_df[batch_df['sentiment'] == batch_df['predicted_sentiment']].shape[0] / batch_df.shape[0]\n",
    "    accuracy_list.append(batch_accuracy)\n",
    "    \n",
    "    print(f\"Batch {i//10 + 1} accuracy: {batch_accuracy}\")\n",
    "    \n",
    "    # Pause for a few seconds to avoid HTTP limit errors\n",
    "    time.sleep(2)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f\"Overall accuracy: {overall_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8063ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = df_test[df_test['sentiment']==df_test['predicted_sentiment']].shape[0]/df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.run(text=review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b40f55c-6f01-4584-a23d-28b5ffae3a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\anaconda3\\envs\\SentimentAnalysis\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\ravip\\anaconda3\\envs\\SentimentAnalysis\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\ravip\\anaconda3\\envs\\SentimentAnalysis\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\AppData\\Local\\Temp\\ipykernel_16956\\1306023653.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch_df['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16956\\1306023653.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m# Load environment variables from .env file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;31m# Access the Hugging Face API key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mhuggingface_api_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HUGGINGFACEHUB_API_TOKEN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# Initialize the LLM with Hugging Face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m flan_t5_llm = HuggingFaceHub(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SentimentAnalysis\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the Hugging Face API key\n",
    "huggingface_api_key = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Initialize the LLM with Hugging Face\n",
    "flan_t5_llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=huggingface_api_key,\n",
    "    repo_id=\"google/flan-t5-large\",\n",
    "    model_kwargs={\"temperature\": 0.1},\n",
    "    task=\"text2text-generation\"\n",
    ")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Given the review, determine the sentiment of the below review: {text}\"\n",
    ")\n",
    "\n",
    "# Create the chain\n",
    "chain = LLMChain(\n",
    "    llm=flan_t5_llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_review(review_):\n",
    "    result = chain.run(text=review_)\n",
    "    return result.strip().lower()\n",
    "\n",
    "# File paths\n",
    "processed_file_path = \"../Data/Process/sample_test_data.xlsx\"\n",
    "batch_status_file_path = \"../Data/Process/batch_status.xlsx\"\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_excel(processed_file_path)\n",
    "\n",
    "# Load or create the batch status file\n",
    "if os.path.exists(batch_status_file_path):\n",
    "    df_status = pd.read_excel(batch_status_file_path)\n",
    "else:\n",
    "    df_status = pd.DataFrame(columns=[\"batch_start\", \"batch_end\", \"status\", \"accuracy\"])\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "# Process each batch\n",
    "for i in range(0, len(df_test), 50):\n",
    "    batch_start = i\n",
    "    batch_end = min(i + 50, len(df_test))\n",
    "    \n",
    "    # Check if the batch has already been processed\n",
    "    if not ((df_status['batch_start'] == batch_start) & (df_status['batch_end'] == batch_end)).any():\n",
    "        batch_df = df_test.iloc[batch_start:batch_end]\n",
    "        batch_df['predicted_sentiment'] = batch_df['review'].apply(classify_review)\n",
    "        \n",
    "        batch_accuracy = batch_df[batch_df['sentiment'] == batch_df['predicted_sentiment']].shape[0] / batch_df.shape[0]\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "        \n",
    "        print(f\"Batch {batch_start//50 + 1} accuracy: {batch_accuracy}\")\n",
    "        \n",
    "        # Create a new DataFrame for the current batch status\n",
    "        batch_status_df = pd.DataFrame({\n",
    "            \"batch_start\": [batch_start],\n",
    "            \"batch_end\": [batch_end],\n",
    "            \"status\": [\"processed\"],\n",
    "            \"accuracy\": [batch_accuracy]\n",
    "        })\n",
    "        \n",
    "        # Concatenate the new batch status DataFrame with the existing status DataFrame\n",
    "        df_status = pd.concat([df_status, batch_status_df], ignore_index=True)\n",
    "        \n",
    "        # Pause for a few seconds to avoid HTTP limit errors\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Save the updated status DataFrame\n",
    "        df_status.to_excel(batch_status_file_path, index=False)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "if accuracy_list:\n",
    "    overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "    print(f\"Overall accuracy: {overall_accuracy}\")\n",
    "else:\n",
    "    print(\"No batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297750b-0212-46f4-a072-ff10bcad89ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SentimentAnalysis)",
   "language": "python",
   "name": "sentimentanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
