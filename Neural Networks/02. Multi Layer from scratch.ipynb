{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499b6782",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4fe246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46690fc1",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bec17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv(os.getcwd()+\"/Data/Iris.csv\")\n",
    "iris_data=iris_data.iloc[np.random.permutation(len(iris_data))].reset_index(drop=True)\n",
    "# iris_data = iris_data_.head(100).reset_index(drop=True)\n",
    "# iris_data_test = iris_data_.tail(50).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "901b17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(iris_data):\n",
    "    species_dic = {'Iris-setosa':[1,0,0], 'Iris-versicolor':[0,1,0], 'Iris-virginica':[0,0,1]}\n",
    "    iris_data['Species_'] = iris_data['Species'].map(lambda x: species_dic[x])\n",
    "    #Normalization\n",
    "    for col in ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']:\n",
    "        iris_data[col] = (iris_data[col] - iris_data[col].min())/ (iris_data[col].max() - iris_data[col].min())\n",
    "    return iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adcdca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = normalization(iris_data)\n",
    "# iris_data_test = normalization(iris_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed43e5",
   "metadata": {},
   "source": [
    "# Three Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d41b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights_layer1 = np.random.randn(4, 8)\n",
    "Weights_layer2 = np.random.randn(8, 5)\n",
    "Weights_layer3 = np.random.randn(5, 3)\n",
    "\n",
    "\n",
    "Bias_layer1 = np.zeros((1, 8))\n",
    "Bias_layer2 = np.zeros((1, 5))\n",
    "Bias_layer3 = np.zeros((1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6878e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85411936,  1.28853836,  2.61343797],\n",
       "       [-0.75745208,  0.51848065, -0.49031599],\n",
       "       [-0.73228694,  0.05253693,  0.79872181],\n",
       "       [ 0.09544274, -0.03481573, -0.14658841],\n",
       "       [ 1.20442419,  0.80603329, -0.84877513]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weights_layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f77d92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bias_layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413470c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "#     return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a330fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function_der(x):\n",
    "    return x*(1-x)\n",
    "#     return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3c67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_farword(X):\n",
    "    output_layer0 = X\n",
    "    output_layer1 = activation_function(np.matmul(X, Weights_layer1) + Bias_layer1)  \n",
    "    output_layer2 = activation_function(np.matmul(output_layer1, Weights_layer2) + Bias_layer2) # (1,8) * (8,5) + (1,5)\n",
    "    output_layer3 = activation_function(np.matmul(output_layer2, Weights_layer3) + Bias_layer3) # (1,5) * (5,3) + (1,3)\n",
    "    return (output_layer0, output_layer1, output_layer2, output_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34dff49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(Y, output_layer0, output_layer1, output_layer2, output_layer3):\n",
    "    global Weights_layer1, Weights_layer2, Weights_layer3, Bias_layer1, Bias_layer2, Bias_layer3\n",
    "    error = 0.33*sum(sum((Y - output_layer3)**2))\n",
    "    \n",
    "    \n",
    "    gradient_layer3 = np.multiply(-1*(Y - output_layer3), activation_function_der(output_layer3)) #(1,3)\n",
    "    Weights_layer3 = Weights_layer3 - learning_rate * np.matmul(gradient_layer3.T, output_layer2).T\n",
    "    Bias_layer3 = Bias_layer3 - learning_rate * gradient_layer3\n",
    "    \n",
    "    \n",
    "    gradient_layer2 = np.multiply(np.matmul(gradient_layer3, Weights_layer3.T), activation_function_der(output_layer2))\n",
    "    Weights_layer2 = Weights_layer2 - learning_rate * np.matmul(gradient_layer2.T, output_layer1).T\n",
    "    Bias_layer2 = Bias_layer2 - learning_rate * gradient_layer2\n",
    "    \n",
    "    \n",
    "    gradient_layer1 = np.multiply(np.matmul(gradient_layer2, Weights_layer2.T), activation_function_der(output_layer1))\n",
    "    Weights_layer1 = Weights_layer1 - learning_rate * np.matmul(gradient_layer1.T, output_layer0).T\n",
    "    Bias_layer1 = Bias_layer1 - learning_rate * gradient_layer1\n",
    "    \n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d4e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(iris_data, output_layer3):\n",
    "    Predicted_Species = []\n",
    "    species_dic = {'Iris-setosa':[1,0,0], 'Iris-versicolor':[0,1,0], 'Iris-virginica':[0,0,1]}\n",
    "    for i in range(0, output_layer3.shape[0]):\n",
    "        Predicted_Species.append(list(species_dic.keys())[np.argmax(output_layer3[i])])\n",
    "    iris_data['Predicted_Species'] = Predicted_Species\n",
    "    return (iris_data[iris_data['Species']==iris_data['Predicted_Species']].shape[0]/iris_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55067b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "Y = iris_data[['Species_']]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "\n",
    "\n",
    "X=np.array(X) #(150, 4)\n",
    "Y = Y.values\n",
    "Y = [i[0] for i in Y]\n",
    "Y = np.array(Y) # (150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d3b089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2806092083688256 0.3333333333333333\n",
      "0.004710438003499211 0.98\n",
      "0.0013321030483074878 0.9866666666666667\n",
      "0.0007801186199264969 0.9866666666666667\n",
      "0.0005388898296986991 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "epoch = 5000\n",
    "learning_rate = 0.01\n",
    "for i in range(0, epoch):\n",
    "    for j in range(0, X.shape[0]):\n",
    "        output_layer0, output_layer1, output_layer2, output_layer3 = feed_farword(X[j,].reshape((1, 4)))\n",
    "        error = back_propagation(Y[j,], output_layer0, output_layer1, output_layer2, output_layer3)\n",
    "    if i%1000==0:\n",
    "        output_layer0, output_layer1, output_layer2, output_layer3 = feed_farword(X)\n",
    "        print(error, get_accuracy(iris_data, output_layer3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e6cb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer0, output_layer1, output_layer2, output_layer3 = feed_farword(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf15983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_Species = []\n",
    "prop = []\n",
    "species_dic = {'Iris-setosa':[1,0,0], 'Iris-versicolor':[0,1,0], 'Iris-virginica':[0,0,1]}\n",
    "for i in range(0, output_layer3.shape[0]):\n",
    "    Predicted_Species.append(list(species_dic.keys())[np.argmax(output_layer3[i])])\n",
    "    prop.append(output_layer3[i].max())\n",
    "iris_data['Predicted_Species'] = Predicted_Species\n",
    "iris_data['Probability'] = prop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e7a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.to_excel(os.getcwd()+\"/Data/Iris_ANN_output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba69d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
